# v0.11: Advanced Branch Workflows

**Theme**: Time-travel and sandboxing — branches become a debugging and safety tool for agents.

Fork/diff/merge shipped in v0.5. v0.11 adds the derivative capabilities that make branches powerful for auditing, debugging, and safe execution of untrusted agents.

> **Note on replay**: Branch replay (deterministic operation-level session reconstruction) was considered and intentionally deferred. It is an application-layer concern better suited to agent orchestration frameworks. Strata provides the primitives — time-travel snapshots, branch export bundles — that make replay possible at the application layer.

> **Surface updates required**: Once each sub-release ships in strata-core, all downstream surfaces must be updated: CLI commands, MCP server tools, Python SDK methods, and Node.js SDK methods. Track this per sub-release.

---

## v0.11.1: Time-Travel Queries

Read any primitive as of a past timestamp. Turns the WAL from an implementation detail into a product feature.

### Value proposition

Agents make sequences of decisions that mutate state. When something goes wrong, developers need to answer "what did the database look like when the agent made that decision?" Today that requires manual logging or replaying from scratch. Time-travel gives instant, read-only access to historical state at any microsecond.

### Epic 1: WAL Timestamp Index

Build a segment-level timestamp index so the WAL can efficiently locate records by time.

**Context**: The WAL already records microsecond timestamps in every record, but segments have no metadata about their timestamp range. Finding records at a target time requires scanning all segments linearly. The timestamp index eliminates this by maintaining per-segment min/max bounds.

| # | User Story | Acceptance Criteria |
|---|-----------|-------------------|
| 1.1 | As a database developer, I need per-segment timestamp bounds tracked during writes so that time-range queries can skip irrelevant segments | Writer tracks min_ts/max_ts as records are appended; bounds persisted when segment closes |
| 1.2 | As a database developer, I need a segment metadata sidecar (or extended header) that stores min/max timestamp, record count, and min/max txn_id | Metadata survives restart; reader loads it without scanning records |
| 1.3 | As a database developer, I need the timestamp index rebuilt on recovery for segments missing metadata (backward compatibility with existing WAL files) | Recovery scans old-format segments once, writes metadata, subsequent starts are fast |
| 1.4 | As a database developer, I need a `find_segments_for_timestamp(target_ts)` API that returns the minimal set of segments containing records at or before the target | Binary search over segment bounds; O(log N) where N = segment count |

### Epic 2: Version-Aware HNSW Index

Make the HNSW vector index temporally aware so that time-travel vector search is a filtered traversal over the existing graph, not a full index reconstruction.

**Context**: Today each `HnswNode` carries a boolean `deleted` flag. The search algorithm already traverses deleted nodes as graph waypoints but excludes them from results. By replacing this flag with a temporal validity window (`created_at`, `deleted_at`), the same traversal logic supports historical queries at zero reconstruction cost.

**Why this works**: The HNSW graph built incrementally over time is a *superset* of any historical state. At timestamp T, nodes inserted after T are filtered from results but their edges still provide connectivity — meaning traversal paths are at least as good as a pure historical index. The approach is strictly sound: no false positives, and recall is equal to or better than reconstruction.

**Current state**: `VectorRecord` (persisted in KV) already stores `created_at` and `updated_at` as microsecond timestamps. `HnswNode` (in-memory graph) only has a boolean `deleted` flag. The change is to propagate the existing timestamps into the in-memory node.

| # | User Story | Acceptance Criteria |
|---|-----------|-------------------|
| 2.1 | As a database developer, I need `HnswNode` to carry `created_at: u64` and `deleted_at: Option<u64>` instead of a boolean `deleted` flag | Node struct updated; `deleted` derived as `deleted_at.is_some()` for backward compat; 16 bytes per node overhead |
| 2.2 | As a database developer, I need insertion to propagate the transaction timestamp from VectorRecord into the HnswNode's `created_at` field | Timestamp flows through: WAL record → VectorRecord → HnswNode |
| 2.3 | As a database developer, I need deletion to set the HnswNode's `deleted_at` to the transaction timestamp instead of setting `deleted = true` | Delete operations carry timestamp; `deleted_at` is written once, never cleared |
| 2.4 | As a database developer, I need the HNSW snapshot format to serialize/deserialize temporal fields (`created_at`, `deleted_at`) instead of the boolean flag | Snapshot format version bump; backward-compatible reader falls back to `created_at=0, deleted_at` derived from old `deleted` flag |
| 2.5 | As a database developer, I need `rebuild_graph()` to restore temporal fields from VectorRecord during recovery | Recovery path: load VectorRecords from KV → extract timestamps → insert into HnswNode |

### Epic 3: Historical State Reconstruction

Given a target timestamp, reconstruct the read-only state of any branch by replaying WAL entries up to that point. Vector search uses the version-aware HNSW index directly.

**Two reconstruction paths**:
- **KV, State, Event, JSON**: WAL-based reconstruction — find nearest checkpoint, replay entries up to target timestamp, return read-only view.
- **Vector**: No reconstruction needed — the live HNSW index is queried with a timestamp filter. The version-aware graph returns only vectors that existed at the target time.

| # | User Story | Acceptance Criteria |
|---|-----------|-------------------|
| 3.1 | As an agent developer, I want to read KV entries as-of a past timestamp so I can see what values my agent was working with when it made a decision | `db.at(timestamp).kv_get(branch, key)` returns the value (or None) as it existed at that time |
| 3.2 | As an agent developer, I want to read state cell values at a past timestamp so I can debug state machine transitions | `db.at(timestamp).state_get(branch, cell)` returns historical value |
| 3.3 | As an agent developer, I want to read event log entries up to a specific timestamp so I can reconstruct the sequence of events that led to a state | `db.at(timestamp).event_list(branch, type)` returns events appended before the cutoff |
| 3.4 | As an agent developer, I want to query JSON documents at a past timestamp so I can see structured data evolution | `db.at(timestamp).json_get(branch, key, path)` returns historical document state |
| 3.5 | As an agent developer, I want to look up individual vectors at a historical point so I can inspect what was stored | `db.at(timestamp).vector_get(branch, collection, key)` returns historical embedding + metadata |
| 3.6 | As an agent developer, I want to run similarity search over a historical snapshot of a vector collection so I can understand what an agent's retrieval context looked like at any point in time | `db.at(timestamp).vector_search(branch, collection, query, k)` uses the version-aware HNSW index with timestamp filtering; returns only vectors that existed at T |
| 3.7 | As a compliance officer, I want provable point-in-time state for audit purposes | Time-travel views are deterministic: same timestamp always produces same result |

### Epic 4: Time-Travel Command/Output Protocol

Expose time-travel through the Command/Output protocol so all surfaces (CLI, MCP, SDKs) get it uniformly.

| # | User Story | Acceptance Criteria |
|---|-----------|-------------------|
| 4.1 | As a database developer, I need new Command variants (or an `as_of` parameter on existing read commands) that carry a target timestamp | Commands are serializable; timestamp is u64 microseconds since epoch |
| 4.2 | As a database developer, I need the executor to route time-travel commands through the reconstruction engine (KV/State/Event/JSON) or the version-aware HNSW search (Vector) depending on primitive type | Time-travel reads never see mutations after the target timestamp |
| 4.3 | As an agent developer, I want time-travel queries to fail gracefully when the target timestamp is before the oldest available WAL entry | Structured error: `HistoryUnavailable { requested_ts, oldest_available_ts }` |
| 4.4 | As an agent developer, I want to list the available time range for a branch so I can know how far back time-travel is possible | `db.time_range(branch)` returns `{ oldest_ts, latest_ts }` |

### Implementation approach

1. **Timestamp axis, not commit ID**: Timestamps are the primary time-travel coordinate. They're already recorded in every WAL record, they're human-meaningful, and they don't require cross-primitive coordination. Commit version remains available as a secondary option if needed later.
2. **Segment metadata sidecar**: Each closed segment gets a `.meta` file (or the segment header is extended to v3) storing `{ min_ts, max_ts, record_count, min_txn_id, max_txn_id }`. Active segment tracks these in memory.
3. **Dual reconstruction strategy**:
   - **KV, State, Event, JSON**: Find nearest checkpoint before target timestamp. Load checkpoint. Replay WAL entries from relevant segments up to target timestamp. Return read-only view.
   - **Vector**: Query the live version-aware HNSW index with `as_of` timestamp. The search algorithm filters nodes by `created_at <= T` and `deleted_at.map_or(true, |d| d > T)`. No reconstruction, no index rebuild. Same cost as a normal search.
4. **Caching**: Frequently accessed time-travel points can be materialized as named snapshots to avoid repeated WAL-based reconstruction (not needed for vector, since the live index serves all timestamps).

### Key files

| Area | Files |
|------|-------|
| WAL format | `crates/durability/src/format/wal_record.rs` |
| WAL writer | `crates/durability/src/wal/writer.rs` |
| WAL reader | `crates/durability/src/wal/reader.rs` |
| HNSW index | `crates/engine/src/primitives/vector/hnsw.rs` |
| HNSW heap | `crates/engine/src/primitives/vector/heap.rs` |
| Vector types | `crates/engine/src/primitives/vector/types.rs` |
| Recovery/replay | `crates/engine/src/recovery/replay.rs`, `crates/durability/src/recovery/replayer.rs` |
| Snapshots | `crates/durability/src/disk_snapshot/` |
| Command protocol | `crates/executor/src/handlers/` |

### Open questions

- Should we support "diff between two timestamps on the same branch" as a first-class operation?
- Is microsecond precision the right granularity, or should we also support "as of transaction N"?
- Should the version-aware HNSW support metadata filter + timestamp filter simultaneously? (Likely yes — they compose naturally.)
- Retention policy interaction: when `retention_apply` trims old versions, should it also compact the HNSW index by removing nodes whose `deleted_at` is older than the retention window?

---

## v0.11.2: Memory Fences (Branch Sandboxing)

Constrain what a branch can read or write. Enables safe execution of untrusted or experimental agents.

### Value proposition

When an agent platform gives an untrusted agent a branch to work in, the platform needs guarantees: the agent can't read secrets it shouldn't see, can't write outside its designated namespace, and can't smuggle unauthorized changes back through a merge. Memory fences make branches into proper security boundaries, not just isolation namespaces.

### Epic 5: Policy Definition

Define the data model and storage for branch-level access policies.

| # | User Story | Acceptance Criteria |
|---|-----------|-------------------|
| 5.1 | As a platform builder, I want to attach a policy to a branch at creation time so that constraints are enforced from the first operation | `db.create_branch("sandbox", policy)` where policy is a structured object |
| 5.2 | As a platform builder, I want to define read/write rules by KV prefix so that an agent can only access its designated namespace | Policy rule: `{ primitive: "kv", prefixes: ["agent_x/*"], access: "read_write" }` |
| 5.3 | As a platform builder, I want to restrict access by primitive type so that an agent is limited to specific data types | Policy rule: `{ primitives: ["kv", "event"], access: "read_write" }` blocks state, json, vector |
| 5.4 | As a platform builder, I want to restrict access by vector collection name so that sensitive embeddings are protected | Policy rule: `{ primitive: "vector", collections: ["public"], access: "read_only" }` |
| 5.5 | As a platform builder, I want to use built-in policy templates for common scenarios so I don't have to write rules from scratch | Templates: `read-only`, `write-only-logging`, `pii-safe` |
| 5.6 | As a platform builder, I want policies to be inspectable so I can audit what constraints are active on any branch | `db.get_branch_policy("sandbox")` returns the full policy |

### Epic 6: Policy Enforcement

Enforce policies at command dispatch time so violations are rejected before reaching the storage layer.

| # | User Story | Acceptance Criteria |
|---|-----------|-------------------|
| 6.1 | As a platform builder, I want policies checked on every command so that no operation bypasses the fence | PolicyGuard runs before handler execution; 100% coverage of write and read commands |
| 6.2 | As a platform builder, I want structured AccessDenied errors when a policy is violated so that agents can handle rejections gracefully | Error includes: policy rule that triggered, the attempted operation, the resource that was blocked |
| 6.3 | As a platform builder, I want read fences that block access to specific keys/collections without revealing their existence | Read violations return NotFound, not AccessDenied (information hiding) |
| 6.4 | As a platform builder, I want write fences that allow reads but block mutations to specific resources | Write-only fences checked only on write commands; reads pass through |
| 6.5 | As a database developer, I need PolicyGuard to compose with the existing AccessMode (ReadOnly/ReadWrite) so that both systems work together without conflicts | AccessMode is checked first (global), then PolicyGuard (branch-level); either can reject |

### Epic 7: Scoped Merges

Limit what data from a sandboxed branch can be merged back to a parent branch.

| # | User Story | Acceptance Criteria |
|---|-----------|-------------------|
| 7.1 | As a platform builder, I want to define merge policies that limit which keys/primitives can be merged back from a sandbox | Merge policy: `{ allow_merge: ["kv:results/*", "event:*"] }` |
| 7.2 | As a platform builder, I want merge to fail explicitly when a sandboxed branch attempts to merge unauthorized changes | Structured error listing all unauthorized changes that would have been merged |
| 7.3 | As a platform builder, I want a "merge preview" that shows what would be merged and what would be blocked before committing | `db.merge_preview(source, target)` returns `{ allowed: [...], blocked: [...] }` |
| 7.4 | As a platform builder, I want scoped merges to work with both LastWriterWins and Strict merge strategies | Policy filtering happens before strategy resolution; blocked entries are excluded from diff |

### Built-in policy templates

| Template | Description | Rules |
|----------|-------------|-------|
| `read-only` | Branch can read all data but write nothing | All primitives: read=allow, write=deny |
| `write-only-logging` | Branch can only append events and write to specific KV prefixes | Event: write=allow; KV `logs/*`: write=allow; all else: write=deny |
| `pii-safe` | Branch cannot access keys matching PII patterns; merge requires review | KV/JSON/State with prefix `pii/*`, `user/*`, `personal/*`: read=deny, write=deny |

### Enforcement architecture

```
Command arrives
    │
    ▼
AccessMode check (global read-only?)
    │ pass
    ▼
PolicyGuard check (branch-level fence?)
    │ pass
    ▼
Handler execution (existing dispatch)
```

PolicyGuard is a trait stored as a database extension (`db.extension::<PolicyGuard>()`), same pattern as AutoEmbedState. Policies are stored alongside branch metadata. PolicyGuard evaluates `(branch_id, command) → Allow | Deny(reason)`.

### Key files

| Area | Files |
|------|-------|
| Policy types | `crates/security/src/policy.rs` (new) |
| PolicyGuard | `crates/security/src/guard.rs` (new) |
| Branch metadata | `crates/engine/src/primitives/branch/index.rs` |
| Command dispatch | `crates/executor/src/handlers/` |
| Merge operations | `crates/engine/src/branch_ops.rs` |

### Open questions

- Should policies be mutable after branch creation, or immutable for security guarantees?
- Should policy violations be logged (audit trail), or is the error response sufficient?
- How do fences interact with transactions? If a transaction touches both allowed and denied resources, does the entire transaction fail or just the denied operations?

---

## Dependencies

- v0.5 (fork/diff/merge — sandboxing and time-travel build on these)
- v0.11.1 is independent of v0.11.2; they can be developed in either order

## Sequencing

```
v0.5 (shipped)
    │
    ├── v0.11.1: Time-Travel Queries
    │     Epic 1: WAL Timestamp Index (foundation)
    │     Epic 2: Version-Aware HNSW Index
    │     Epic 3: Historical State Reconstruction
    │     Epic 4: Command/Output Protocol
    │
    └── v0.11.2: Memory Fences
          Epic 5: Policy Definition
          Epic 6: Policy Enforcement
          Epic 7: Scoped Merges
```

v0.11.1 is recommended first — the WAL timestamp index is foundational infrastructure that benefits compaction, debugging, and future features beyond time-travel. The version-aware HNSW index is a low-cost, high-value change (16 bytes per node) that eliminates the most expensive reconstruction path and makes historical vector search a first-class capability.
